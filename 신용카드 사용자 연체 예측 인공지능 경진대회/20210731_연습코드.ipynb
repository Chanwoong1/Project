{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import warnings, random\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.metrics import log_loss, confusion_matrix, precision_score, recall_score, f1_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, validation_curve, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "import matplotlib\n",
    "import mglearn\n",
    "import joblib\n",
    "import math\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from statsmodels.graphics.tsaplots import plot_acf, acf\n",
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet, LinearRegression, SGDRegressor, LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.compose import make_column_transformer,ColumnTransformer\n",
    "import math\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import sklearn.metrics as metrics\n",
    "from xgboost import XGBClassifier, XGBRFRegressor, XGBRegressor\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "import os\n",
    "\n",
    "matplotlib.rcParams['font.family']='Malgun Gothic'\n",
    "plt.rcParams['font.size']=14\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version : 1.19.2\n",
      "pandas version : 1.2.4\n",
      "matplotlib version : 3.3.2\n"
     ]
    }
   ],
   "source": [
    "print('numpy version :', np.__version__)\n",
    "print('pandas version :', pd.__version__)\n",
    "print('matplotlib version :', mpl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './data'\n",
    "train_path = os.path.join(BASE_DIR, 'train.csv')\n",
    "test_path = os.path.join(BASE_DIR, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "target = train['credit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna('NaN', inplace=True) \n",
    "test.fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 이상치 처리\n",
    "- train['family_size'] > 7 인 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['family_size'] <= 7)]\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 의미없는 변수 제거\n",
    "- index 제거\n",
    "- FLAG_MOBIL 삭제:모든 값이 1로 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['index', 'FLAG_MOBIL'], axis=1, inplace=True)\n",
    "test.drop(['index', 'FLAG_MOBIL'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DAYS_EMPLOYED\n",
    "- 양수인 데이터는 현재 무직자로 판단, 0 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "test['DAYS_EMPLOYED'] = test['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DAYS_BIRTH, begin_month, DAYS_EMPLOYED\n",
    "- 음수값 -> 양수 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
    "for feat in feats:\n",
    "    train[feat]=np.abs(train[feat])\n",
    "    test[feat]=np.abs(test[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 파생변수\n",
    "- numeric 변수는 최대한 다양한 특징을 보일 수 있도록 생성\n",
    "- category 변수는 여러가지를 조합해 보았지만 전체 변수를 합친 ID 하나만 만들었을때 가장 logloss가 낮았음\n",
    "- ref) rollcake님 글 https://dacon.io/competitions/official/235713/codeshare/2526?page=1&dtype=recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    # before_EMPLOYED: 고용되기 전까지의 일수\n",
    "    df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
    "    df['income_total_befofeEMP_ratio'] = df['income_total'] / df['before_EMPLOYED']\n",
    "    df['before_EMPLOYED_m'] = np.floor(df['before_EMPLOYED'] / 30) - ((np.floor(df['before_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "    df['before_EMPLOYED_w'] = np.floor(df['before_EMPLOYED'] / 7) - ((np.floor(df['before_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "    \n",
    "    #DAYS_BIRTH 파생변수- Age(나이), 태어난 월, 태어난 주(출생연도의 n주차)\n",
    "    df['Age'] = df['DAYS_BIRTH'] // 365\n",
    "    df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) - ((np.floor(df['DAYS_BIRTH'] / 30) / 12).astype(int) * 12)\n",
    "    df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) - ((np.floor(df['DAYS_BIRTH'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "    \n",
    "    #DAYS_EMPLOYED_m 파생변수- EMPLOYED(근속연수), DAYS_EMPLOYED_m(고용된 달) ,DAYS_EMPLOYED_w(고용된 주(고용연도의 n주차))  \n",
    "    df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
    "    df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) - ((np.floor(df['DAYS_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "    df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) - ((np.floor(df['DAYS_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "    #ability: 소득/(살아온 일수+ 근무일수)\n",
    "    df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'])\n",
    "    \n",
    "    #income_mean: 소득/ 가족 수\n",
    "    df['income_mean'] = df['income_total'] / df['family_size']\n",
    "    \n",
    "    #ID 생성: 각 컬럼의 값들을 더해서 고유한 사람을 파악(*한 사람이 여러 개 카드를 만들 가능성을 고려해 begin_month는 제외함)\n",
    "    df['ID'] = \\\n",
    "    df['child_num'].astype(str) + '_' + df['income_total'].astype(str) + '_' +\\\n",
    "    df['DAYS_BIRTH'].astype(str) + '_' + df['DAYS_EMPLOYED'].astype(str) + '_' +\\\n",
    "    df['work_phone'].astype(str) + '_' + df['phone'].astype(str) + '_' +\\\n",
    "    df['email'].astype(str) + '_' + df['family_size'].astype(str) + '_' +\\\n",
    "    df['gender'].astype(str) + '_' + df['car'].astype(str) + '_' +\\\n",
    "    df['reality'].astype(str) + '_' + df['income_type'].astype(str) + '_' +\\\n",
    "    df['edu_type'].astype(str) + '_' + df['family_type'].astype(str) + '_' +\\\n",
    "    df['house_type'].astype(str) + '_' + df['occyp_type'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 파생변수와 다중공선을 보이는 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED',]\n",
    "train.drop(cols, axis=1, inplace=True)\n",
    "test.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling, Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Numeric, Category 컬럼 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Numerical features:  18\n",
      "Number of Categorical features:  9\n"
     ]
    }
   ],
   "source": [
    "numerical_feats = train.dtypes[train.dtypes != \"object\"].index.tolist()\n",
    "numerical_feats.remove('credit')\n",
    "print(\"Number of Numerical features: \", len(numerical_feats))\n",
    "\n",
    "categorical_feats = train.dtypes[train.dtypes == \"object\"].index.tolist()\n",
    "print(\"Number of Categorical features: \", len(categorical_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['income_total',\n",
       " 'work_phone',\n",
       " 'phone',\n",
       " 'email',\n",
       " 'family_size',\n",
       " 'begin_month',\n",
       " 'before_EMPLOYED',\n",
       " 'income_total_befofeEMP_ratio',\n",
       " 'before_EMPLOYED_m',\n",
       " 'before_EMPLOYED_w',\n",
       " 'Age',\n",
       " 'DAYS_BIRTH_m',\n",
       " 'DAYS_BIRTH_w',\n",
       " 'EMPLOYED',\n",
       " 'DAYS_EMPLOYED_m',\n",
       " 'DAYS_EMPLOYED_w',\n",
       " 'ability',\n",
       " 'income_mean']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'car',\n",
       " 'reality',\n",
       " 'income_type',\n",
       " 'edu_type',\n",
       " 'family_type',\n",
       " 'house_type',\n",
       " 'occyp_type',\n",
       " 'ID']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Log Scale\n",
    "- income_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df['income_total'] = np.log1p(1+df['income_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.612327\n",
       "1       2.625613\n",
       "2       2.576214\n",
       "3       2.612327\n",
       "4       2.661927\n",
       "          ...   \n",
       "9995    2.654544\n",
       "9996    2.654544\n",
       "9997    2.680078\n",
       "9998    2.646226\n",
       "9999    2.674575\n",
       "Name: income_total, Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log1p(1+df['income_total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. OrdinalEncoder\n",
    "- 카테고리 변수는 ordinal_encoder 변환\n",
    "- ID는 변환 후 정수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(categorical_feats)\n",
    "train[categorical_feats] = encoder.fit_transform(train[categorical_feats], train['credit'])\n",
    "test[categorical_feats] = encoder.transform(test[categorical_feats])\n",
    "\n",
    "train['ID'] = train['ID'].astype('int64')\n",
    "test['ID'] = test['ID'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 클러스터링 구성\n",
    "- 타겟을 결정짓는 뚜렷한 특징을 갖는 피쳐를 찾지 못해 clustering 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_train = train.drop(['credit'], axis=1)\n",
    "kmeans = KMeans(n_clusters=36, random_state=42).fit(kmeans_train)\n",
    "train['cluster'] = kmeans.predict(kmeans_train)\n",
    "test['cluster'] = kmeans.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. StandardScale\n",
    "- 이미 로그변환을 진행한 income_total을 제외한 나머지 numeric 컬럼 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats.remove('income_total')\n",
    "scaler = StandardScaler()\n",
    "train[numerical_feats] = scaler.fit_transform(train[numerical_feats])\n",
    "test[numerical_feats] = scaler.transform(test[numerical_feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling - catboost\n",
    "- fold 수를 5부터 17까지 돌려보고 최적 fold 15로 판단 후 선택\n",
    "- parameter를 default로 두는 것이 logloss가 가장 낮았음\n",
    "- ref) Catboost Documentation - https://catboost.ai/docs/concepts/python-reference_catboostclassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 2000\n",
    "seed = 42\n",
    "n_fold = 15\n",
    "n_class = 3\n",
    "\n",
    "target = 'credit'\n",
    "X = train.drop(target, axis=1)\n",
    "y = train[target]\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------- Fold 0 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0346960\ttest: 1.0333820\tbest: 1.0333820 (0)\ttotal: 172ms\tremaining: 2m 51s\n",
      "100:\tlearn: 0.7044704\ttest: 0.6427096\tbest: 0.6427096 (100)\ttotal: 4.49s\tremaining: 39.9s\n",
      "200:\tlearn: 0.6843687\ttest: 0.6403953\tbest: 0.6402982 (176)\ttotal: 9.31s\tremaining: 37s\n",
      "300:\tlearn: 0.6680286\ttest: 0.6392776\tbest: 0.6392019 (296)\ttotal: 13.9s\tremaining: 32.3s\n",
      "400:\tlearn: 0.6515064\ttest: 0.6392338\tbest: 0.6388684 (397)\ttotal: 18.4s\tremaining: 27.5s\n",
      "500:\tlearn: 0.6338447\ttest: 0.6414953\tbest: 0.6386980 (412)\ttotal: 22.7s\tremaining: 22.6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6386980408\n",
      "bestIteration = 412\n",
      "\n",
      "Shrink model to first 413 iterations.\n",
      "CV Log Loss Score: 0.638698\n",
      "\n",
      "----------------- Fold 1 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0346110\ttest: 1.0339653\tbest: 1.0339653 (0)\ttotal: 12.5ms\tremaining: 12.5s\n",
      "100:\tlearn: 0.7034876\ttest: 0.6759823\tbest: 0.6757272 (93)\ttotal: 3.9s\tremaining: 34.7s\n",
      "200:\tlearn: 0.6850424\ttest: 0.6757861\tbest: 0.6751435 (181)\ttotal: 8.42s\tremaining: 33.5s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6751434693\n",
      "bestIteration = 181\n",
      "\n",
      "Shrink model to first 182 iterations.\n",
      "CV Log Loss Score: 0.675143\n",
      "\n",
      "----------------- Fold 2 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0344416\ttest: 1.0352826\tbest: 1.0352826 (0)\ttotal: 12.5ms\tremaining: 12.5s\n",
      "100:\tlearn: 0.7036051\ttest: 0.6489458\tbest: 0.6487653 (98)\ttotal: 4.08s\tremaining: 36.3s\n",
      "200:\tlearn: 0.6850680\ttest: 0.6491882\tbest: 0.6481854 (119)\ttotal: 8.31s\tremaining: 33s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.648185394\n",
      "bestIteration = 119\n",
      "\n",
      "Shrink model to first 120 iterations.\n",
      "CV Log Loss Score: 0.648185\n",
      "\n",
      "----------------- Fold 3 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0343459\ttest: 1.0361116\tbest: 1.0361116 (0)\ttotal: 12.5ms\tremaining: 12.4s\n",
      "100:\tlearn: 0.7039063\ttest: 0.6542232\tbest: 0.6542034 (99)\ttotal: 3.98s\tremaining: 35.5s\n",
      "200:\tlearn: 0.6838496\ttest: 0.6493739\tbest: 0.6493739 (200)\ttotal: 8.14s\tremaining: 32.3s\n",
      "300:\tlearn: 0.6665829\ttest: 0.6477070\tbest: 0.6475397 (296)\ttotal: 12.4s\tremaining: 28.8s\n",
      "400:\tlearn: 0.6491826\ttest: 0.6465468\tbest: 0.6462412 (362)\ttotal: 16.6s\tremaining: 24.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.646241213\n",
      "bestIteration = 362\n",
      "\n",
      "Shrink model to first 363 iterations.\n",
      "CV Log Loss Score: 0.646241\n",
      "\n",
      "----------------- Fold 4 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0345362\ttest: 1.0346529\tbest: 1.0346529 (0)\ttotal: 13.4ms\tremaining: 13.4s\n",
      "100:\tlearn: 0.7026560\ttest: 0.6686018\tbest: 0.6684092 (98)\ttotal: 3.95s\tremaining: 35.1s\n",
      "200:\tlearn: 0.6842462\ttest: 0.6684739\tbest: 0.6682346 (135)\ttotal: 8.33s\tremaining: 33.1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6682346059\n",
      "bestIteration = 135\n",
      "\n",
      "Shrink model to first 136 iterations.\n",
      "CV Log Loss Score: 0.668235\n",
      "\n",
      "----------------- Fold 5 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0346355\ttest: 1.0337960\tbest: 1.0337960 (0)\ttotal: 14ms\tremaining: 14s\n",
      "100:\tlearn: 0.7009499\ttest: 0.6734212\tbest: 0.6734212 (100)\ttotal: 3.95s\tremaining: 35.2s\n",
      "200:\tlearn: 0.6802634\ttest: 0.6729243\tbest: 0.6725509 (187)\ttotal: 8.11s\tremaining: 32.2s\n",
      "300:\tlearn: 0.6622096\ttest: 0.6727598\tbest: 0.6718149 (254)\ttotal: 12.4s\tremaining: 28.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6718148789\n",
      "bestIteration = 254\n",
      "\n",
      "Shrink model to first 255 iterations.\n",
      "CV Log Loss Score: 0.671815\n",
      "\n",
      "----------------- Fold 6 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0356731\ttest: 1.0344898\tbest: 1.0344898 (0)\ttotal: 45.5ms\tremaining: 45.4s\n",
      "100:\tlearn: 0.7037981\ttest: 0.6663075\tbest: 0.6662509 (99)\ttotal: 3.95s\tremaining: 35.2s\n",
      "200:\tlearn: 0.6838192\ttest: 0.6650565\tbest: 0.6643402 (185)\ttotal: 8.01s\tremaining: 31.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6643401989\n",
      "bestIteration = 185\n",
      "\n",
      "Shrink model to first 186 iterations.\n",
      "CV Log Loss Score: 0.664340\n",
      "\n",
      "----------------- Fold 7 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0345715\ttest: 1.0351628\tbest: 1.0351628 (0)\ttotal: 36.6ms\tremaining: 36.5s\n",
      "100:\tlearn: 0.7035536\ttest: 0.6789351\tbest: 0.6789070 (93)\ttotal: 3.94s\tremaining: 35.1s\n",
      "200:\tlearn: 0.6832570\ttest: 0.6757529\tbest: 0.6752324 (189)\ttotal: 8.04s\tremaining: 32s\n",
      "300:\tlearn: 0.6670520\ttest: 0.6754091\tbest: 0.6750633 (220)\ttotal: 12.4s\tremaining: 28.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6750632617\n",
      "bestIteration = 220\n",
      "\n",
      "Shrink model to first 221 iterations.\n",
      "CV Log Loss Score: 0.675063\n",
      "\n",
      "----------------- Fold 8 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0353271\ttest: 1.0367616\tbest: 1.0367616 (0)\ttotal: 57.5ms\tremaining: 57.4s\n",
      "100:\tlearn: 0.7023225\ttest: 0.6785303\tbest: 0.6785303 (100)\ttotal: 3.92s\tremaining: 34.9s\n",
      "200:\tlearn: 0.6844366\ttest: 0.6778511\tbest: 0.6775951 (167)\ttotal: 8.12s\tremaining: 32.3s\n",
      "300:\tlearn: 0.6653033\ttest: 0.6772128\tbest: 0.6768504 (293)\ttotal: 12.3s\tremaining: 28.6s\n",
      "400:\tlearn: 0.6473431\ttest: 0.6783491\tbest: 0.6764797 (341)\ttotal: 16.6s\tremaining: 24.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6764797248\n",
      "bestIteration = 341\n",
      "\n",
      "Shrink model to first 342 iterations.\n",
      "CV Log Loss Score: 0.676480\n",
      "\n",
      "----------------- Fold 9 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0346637\ttest: 1.0346430\tbest: 1.0346430 (0)\ttotal: 41.5ms\tremaining: 41.5s\n",
      "100:\tlearn: 0.7048652\ttest: 0.6568705\tbest: 0.6568705 (100)\ttotal: 4.05s\tremaining: 36s\n",
      "200:\tlearn: 0.6856532\ttest: 0.6534331\tbest: 0.6534331 (200)\ttotal: 8.33s\tremaining: 33.1s\n",
      "300:\tlearn: 0.6671916\ttest: 0.6534666\tbest: 0.6532546 (202)\ttotal: 12.8s\tremaining: 29.8s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6532545671\n",
      "bestIteration = 202\n",
      "\n",
      "Shrink model to first 203 iterations.\n",
      "CV Log Loss Score: 0.653255\n",
      "\n",
      "----------------- Fold 10 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0345792\ttest: 1.0350566\tbest: 1.0350566 (0)\ttotal: 36.1ms\tremaining: 36s\n",
      "100:\tlearn: 0.7040088\ttest: 0.6660378\tbest: 0.6660378 (100)\ttotal: 3.98s\tremaining: 35.4s\n",
      "200:\tlearn: 0.6839917\ttest: 0.6628509\tbest: 0.6628123 (199)\ttotal: 8.29s\tremaining: 32.9s\n",
      "300:\tlearn: 0.6667224\ttest: 0.6639842\tbest: 0.6624486 (206)\ttotal: 12.5s\tremaining: 29s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6624485749\n",
      "bestIteration = 206\n",
      "\n",
      "Shrink model to first 207 iterations.\n",
      "CV Log Loss Score: 0.662449\n",
      "\n",
      "----------------- Fold 11 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0345824\ttest: 1.0349800\tbest: 1.0349800 (0)\ttotal: 38.2ms\tremaining: 38.1s\n",
      "100:\tlearn: 0.7021271\ttest: 0.6929493\tbest: 0.6929012 (97)\ttotal: 3.93s\tremaining: 35s\n",
      "200:\tlearn: 0.6843244\ttest: 0.6916146\tbest: 0.6910816 (179)\ttotal: 8.11s\tremaining: 32.2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6910815521\n",
      "bestIteration = 179\n",
      "\n",
      "Shrink model to first 180 iterations.\n",
      "CV Log Loss Score: 0.691082\n",
      "\n",
      "----------------- Fold 12 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0355737\ttest: 1.0356150\tbest: 1.0356150 (0)\ttotal: 44ms\tremaining: 44s\n",
      "100:\tlearn: 0.7049106\ttest: 0.6598953\tbest: 0.6598953 (100)\ttotal: 4.15s\tremaining: 37s\n",
      "200:\tlearn: 0.6867650\ttest: 0.6573934\tbest: 0.6572431 (188)\ttotal: 8.29s\tremaining: 33s\n",
      "300:\tlearn: 0.6695676\ttest: 0.6567470\tbest: 0.6562239 (264)\ttotal: 12.4s\tremaining: 28.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6562239203\n",
      "bestIteration = 264\n",
      "\n",
      "Shrink model to first 265 iterations.\n",
      "CV Log Loss Score: 0.656224\n",
      "\n",
      "----------------- Fold 13 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0357358\ttest: 1.0346673\tbest: 1.0346673 (0)\ttotal: 48.4ms\tremaining: 48.4s\n",
      "100:\tlearn: 0.7019788\ttest: 0.6847157\tbest: 0.6844540 (85)\ttotal: 3.98s\tremaining: 35.5s\n",
      "200:\tlearn: 0.6819816\ttest: 0.6836538\tbest: 0.6835509 (198)\ttotal: 8.33s\tremaining: 33.1s\n",
      "300:\tlearn: 0.6634154\ttest: 0.6842024\tbest: 0.6830530 (222)\ttotal: 12.5s\tremaining: 29s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6830530121\n",
      "bestIteration = 222\n",
      "\n",
      "Shrink model to first 223 iterations.\n",
      "CV Log Loss Score: 0.683053\n",
      "\n",
      "----------------- Fold 14 -----------------\n",
      "\n",
      "Learning rate set to 0.115127\n",
      "0:\tlearn: 1.0346954\ttest: 1.0340314\tbest: 1.0340314 (0)\ttotal: 43.9ms\tremaining: 43.9s\n",
      "100:\tlearn: 0.7061306\ttest: 0.6740026\tbest: 0.6740026 (100)\ttotal: 3.86s\tremaining: 34.4s\n",
      "200:\tlearn: 0.6865332\ttest: 0.6718720\tbest: 0.6717625 (197)\ttotal: 8.03s\tremaining: 31.9s\n",
      "300:\tlearn: 0.6668860\ttest: 0.6697020\tbest: 0.6695870 (299)\ttotal: 12.2s\tremaining: 28.4s\n",
      "400:\tlearn: 0.6495369\ttest: 0.6701000\tbest: 0.6692944 (317)\ttotal: 16.4s\tremaining: 24.6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.669294369\n",
      "bestIteration = 317\n",
      "\n",
      "Shrink model to first 318 iterations.\n",
      "CV Log Loss Score: 0.669294\n",
      "\tLog Loss: 0.665302\n"
     ]
    }
   ],
   "source": [
    "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "folds=[]\n",
    "for train_idx, valid_idx in skfold.split(X, y):\n",
    "        folds.append((train_idx, valid_idx))\n",
    "\n",
    "cat_pred = np.zeros((X.shape[0], n_class))\n",
    "cat_pred_test = np.zeros((X_test.shape[0], n_class))\n",
    "cat_cols = ['income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type', 'ID']\n",
    "for fold in range(n_fold):\n",
    "  print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
    "  train_idx, valid_idx = folds[fold]\n",
    "  X_train, X_valid, y_train, y_valid = X.iloc[train_idx], X.iloc[valid_idx], y[train_idx], y[valid_idx]\n",
    "  train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
    "  valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
    "\n",
    "  model_cat = CatBoostClassifier()\n",
    "  model_cat.fit(train_data, eval_set=valid_data, use_best_model=True, early_stopping_rounds=100, verbose=100)\n",
    "  \n",
    "  cat_pred[valid_idx] = model_cat.predict_proba(X_valid)\n",
    "  cat_pred_test += model_cat.predict_proba(X_test) / n_fold\n",
    "  print(f'CV Log Loss Score: {log_loss(y_valid, cat_pred[valid_idx]):.6f}')\n",
    "    \n",
    "print(f'\\tLog Loss: {log_loss(y, cat_pred):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'credit'\n",
    "X = train.drop(target, axis=1)\n",
    "y = train[target]\n",
    "X_test = test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>DAYS_BIRTH_m</th>\n",
       "      <th>DAYS_BIRTH_w</th>\n",
       "      <th>EMPLOYED</th>\n",
       "      <th>DAYS_EMPLOYED_m</th>\n",
       "      <th>DAYS_EMPLOYED_w</th>\n",
       "      <th>ability</th>\n",
       "      <th>income_mean</th>\n",
       "      <th>ID</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.218505</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>-0.645632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452826</td>\n",
       "      <td>0.442795</td>\n",
       "      <td>-0.443485</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>-1.230046</td>\n",
       "      <td>-1.077087</td>\n",
       "      <td>-0.032496</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.419174</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>-0.645632</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.060773</td>\n",
       "      <td>0.442795</td>\n",
       "      <td>-0.443485</td>\n",
       "      <td>-0.250471</td>\n",
       "      <td>-0.424295</td>\n",
       "      <td>-1.077087</td>\n",
       "      <td>1.190137</td>\n",
       "      <td>-0.254157</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13.017007</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>1.548870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763069</td>\n",
       "      <td>-1.582567</td>\n",
       "      <td>0.451504</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>-0.424295</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>1.186515</td>\n",
       "      <td>1.693108</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.218505</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>1.548870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192277</td>\n",
       "      <td>1.310808</td>\n",
       "      <td>1.346494</td>\n",
       "      <td>-0.094880</td>\n",
       "      <td>1.187206</td>\n",
       "      <td>0.629874</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11.967193</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>-0.645632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192277</td>\n",
       "      <td>1.021471</td>\n",
       "      <td>-1.338475</td>\n",
       "      <td>-0.094880</td>\n",
       "      <td>1.455790</td>\n",
       "      <td>-1.077087</td>\n",
       "      <td>-0.282885</td>\n",
       "      <td>-0.305401</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26446</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.323865</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>-0.645632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.887074</td>\n",
       "      <td>0.153458</td>\n",
       "      <td>-0.443485</td>\n",
       "      <td>-0.094880</td>\n",
       "      <td>0.381456</td>\n",
       "      <td>1.483355</td>\n",
       "      <td>0.723641</td>\n",
       "      <td>-0.612864</td>\n",
       "      <td>3301</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26447</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.100723</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>-0.645632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192277</td>\n",
       "      <td>-0.135880</td>\n",
       "      <td>-1.338475</td>\n",
       "      <td>0.060710</td>\n",
       "      <td>1.455790</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>-0.143427</td>\n",
       "      <td>-0.151670</td>\n",
       "      <td>8753</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26448</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12.586227</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>-0.645632</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.408172</td>\n",
       "      <td>-1.582567</td>\n",
       "      <td>-1.338475</td>\n",
       "      <td>-0.094880</td>\n",
       "      <td>0.650039</td>\n",
       "      <td>1.483355</td>\n",
       "      <td>1.932411</td>\n",
       "      <td>0.616988</td>\n",
       "      <td>8754</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26449</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.049431</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>-0.645632</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.408172</td>\n",
       "      <td>-1.003892</td>\n",
       "      <td>-0.443485</td>\n",
       "      <td>-0.872832</td>\n",
       "      <td>-0.424295</td>\n",
       "      <td>1.483355</td>\n",
       "      <td>0.824160</td>\n",
       "      <td>0.955197</td>\n",
       "      <td>8755</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.302229</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.538321</td>\n",
       "      <td>-0.645632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849919</td>\n",
       "      <td>-0.425217</td>\n",
       "      <td>1.346494</td>\n",
       "      <td>-0.561651</td>\n",
       "      <td>1.187206</td>\n",
       "      <td>-1.077087</td>\n",
       "      <td>-1.059040</td>\n",
       "      <td>-0.828088</td>\n",
       "      <td>8756</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26451 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  car  reality  income_total  income_type  edu_type  family_type  \\\n",
       "0           1    1        1     12.218505            1         1            1   \n",
       "1           1    1        2     12.419174            1         2            2   \n",
       "2           2    2        2     13.017007            2         1            1   \n",
       "3           1    1        2     12.218505            1         2            1   \n",
       "4           1    2        2     11.967193            3         1            1   \n",
       "...       ...  ...      ...           ...          ...       ...          ...   \n",
       "26446       1    1        1     12.323865            3         2            1   \n",
       "26447       1    1        2     12.100723            2         1            3   \n",
       "26448       1    2        1     12.586227            2         2            2   \n",
       "26449       2    1        2     12.049431            2         3            4   \n",
       "26450       1    1        1     11.302229            2         2            2   \n",
       "\n",
       "       house_type  work_phone     phone  ...       Age  DAYS_BIRTH_m  \\\n",
       "0               1   -0.538321 -0.645632  ... -0.452826      0.442795   \n",
       "1               2   -0.538321 -0.645632  ... -1.060773      0.442795   \n",
       "2               2   -0.538321  1.548870  ...  0.763069     -1.582567   \n",
       "3               2   -0.538321  1.548870  ... -0.192277      1.310808   \n",
       "4               2   -0.538321 -0.645632  ... -0.192277      1.021471   \n",
       "...           ...         ...       ...  ...       ...           ...   \n",
       "26446           2   -0.538321 -0.645632  ... -0.887074      0.153458   \n",
       "26447           2   -0.538321 -0.645632  ... -0.192277     -0.135880   \n",
       "26448           3   -0.538321 -0.645632  ... -1.408172     -1.582567   \n",
       "26449           2   -0.538321 -0.645632  ... -1.408172     -1.003892   \n",
       "26450           2   -0.538321 -0.645632  ...  0.849919     -0.425217   \n",
       "\n",
       "       DAYS_BIRTH_w  EMPLOYED  DAYS_EMPLOYED_m  DAYS_EMPLOYED_w   ability  \\\n",
       "0         -0.443485  0.994253        -1.230046        -1.077087 -0.032496   \n",
       "1         -0.443485 -0.250471        -0.424295        -1.077087  1.190137   \n",
       "2          0.451504  0.994253        -0.424295        -0.223607  1.186515   \n",
       "3          1.346494 -0.094880         1.187206         0.629874  0.101168   \n",
       "4         -1.338475 -0.094880         1.455790        -1.077087 -0.282885   \n",
       "...             ...       ...              ...              ...       ...   \n",
       "26446     -0.443485 -0.094880         0.381456         1.483355  0.723641   \n",
       "26447     -1.338475  0.060710         1.455790        -0.223607 -0.143427   \n",
       "26448     -1.338475 -0.094880         0.650039         1.483355  1.932411   \n",
       "26449     -0.443485 -0.872832        -0.424295         1.483355  0.824160   \n",
       "26450      1.346494 -0.561651         1.187206        -1.077087 -1.059040   \n",
       "\n",
       "       income_mean    ID  cluster  \n",
       "0         0.002062     1       35  \n",
       "1        -0.254157     2        7  \n",
       "2         1.693108     3       18  \n",
       "3         0.002062     4       35  \n",
       "4        -0.305401     5        7  \n",
       "...            ...   ...      ...  \n",
       "26446    -0.612864  3301       31  \n",
       "26447    -0.151670  8753       10  \n",
       "26448     0.616988  8754       32  \n",
       "26449     0.955197  8755       13  \n",
       "26450    -0.828088  8756       23  \n",
       "\n",
       "[26451 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: min_samples_leaf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('lgbmclassifier',\n",
       "                 LGBMClassifier(learning_rate=0.05, max_depth=5,\n",
       "                                min_samples_leaf=1))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb = make_pipeline(StandardScaler(), LGBMClassifier(learning_rate = 0.05, max_depth = 5, min_samples_leaf = 1, n_estimators = 100))\n",
    "model_lgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1536 candidates, totalling 7680 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-22d817841ff2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m               }\n\u001b[0;32m      9\u001b[0m \u001b[0mgridSearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgridSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "model_xgb = Pipeline( [ ('scl', StandardScaler()), ('xgb', XGBClassifier(n_jobs = 12)) ] )\n",
    "param_value = {'xgb__n_estimators' : [200, 250, 300, 350],\n",
    "               'xgb__learning_rate' : [0.01, 0.05, 0.1, 0.5],\n",
    "               'xgb__max_depth' : list(range(2, 20, 3)),\n",
    "               'xgb__subsample' : [0.25, 0.5, 0.75, 1],\n",
    "               'xgb__min_child_weight' : [0.5, 1, 1.5, 2]\n",
    "              }\n",
    "gridSearch = GridSearchCV(model_xgb, param_grid = param_value, cv = 5, n_jobs = 12, verbose = 1)\n",
    "gridSearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = Pipeline( [ ('scl', StandardScaler()), ('xgb', XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "                              colsample_bylevel=1, colsample_bynode=1,\n",
    "                              colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "                              importance_type='gain',\n",
    "                              interaction_constraints='', learning_rate=0.05,\n",
    "                              max_delta_step=0, max_depth=17, min_child_weight=1.5,\n",
    "                              monotone_constraints='()',\n",
    "                              n_estimators=300, n_jobs=12, num_parallel_tree=1,\n",
    "                              random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "                              scale_pos_weight=1, subsample=0.5,\n",
    "                              tree_method='exact', validate_parameters=1,\n",
    "                              verbosity=None)) ] )\n",
    "model_xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feautre Importance\n",
    "- ID의 중요도가 상당히 높게 나오는 것을 볼 수 있었음\n",
    "- plot_feature_importance 함수\n",
    "- ref) https://stackoverflow.com/questions/64988694/how-can-i-get-the-feature-importance-of-a-catboost-in-a-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "    \n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(model_cat.get_feature_importance(),X_test.columns,'CATBOOST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(os.path.join(BASE_DIR, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y, model_lgb.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y, model_xgb.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.iloc[:, 1:] = model_lgb.predict_proba(test)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('20210731_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
